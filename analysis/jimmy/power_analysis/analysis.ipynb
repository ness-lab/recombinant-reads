{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pysam\n",
    "import numpy.random as r\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-sequence with coverage of 1\n",
    "\n",
    "VCF2FASTA_FILEPATH = 'output/vcf2fasta.fasta'\n",
    "ANALYSIS_SCRIPT = 'analysis.py'\n",
    "\n",
    "# run analysis.py to create fasta sequence with phase change\n",
    "# and generate reads with art_illumina\n",
    "\n",
    "COVERAGE = 1\n",
    "PERCENTAGE = 0.0004\n",
    "BASE_COUNT = 1000000\n",
    "ANALYSIS_OUTPUT = 'output/unfiltered'\n",
    "FILTERED_OUTPUT = 'output/filtered'\n",
    "window_counts = open('output/window_counts.tsv', 'w')\n",
    "\n",
    "iteration = 1\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    subprocess.run(map(str, ['python3', 'analysis.py',\n",
    "                    '-f', VCF2FASTA_FILEPATH,\n",
    "                    '-e', BASE_COUNT,\n",
    "                    '-c', COVERAGE,\n",
    "                    '-p', PERCENTAGE,\n",
    "                    '-o', ANALYSIS_OUTPUT + str(iteration)]))\n",
    "\n",
    "    # read last line of output/phase_change_log.txt \n",
    "    # that analysis.py writes to get list of phase changes\n",
    "\n",
    "    phase_changes = subprocess.check_output(['tail', '-1', 'output/phase_change_log.txt']).decode('utf-8').strip()\n",
    "\n",
    "    phase_changes = ast.literal_eval(phase_changes)\n",
    "\n",
    "\n",
    "    # run readcomb on output of art_illumina\n",
    "\n",
    "\n",
    "    subprocess.run(['readcomb-filter',\n",
    "                    '-b', ANALYSIS_OUTPUT + str(iteration) + '.sam',\n",
    "                    '-v', '../data/filtered_full.vcf.gz',\n",
    "                    '-p', '4',\n",
    "                    '-o', FILTERED_OUTPUT + str(iteration)])\n",
    "\n",
    "    # sort and index the readcomb-filtered and unfiltered sam files\n",
    "\n",
    "    with open(ANALYSIS_OUTPUT + str(iteration) + 'sorted.bam', 'w') as f:\n",
    "        subprocess.call(['samtools', 'sort', ANALYSIS_OUTPUT + str(iteration) + '.sam'], stdout=f)\n",
    "\n",
    "    subprocess.run(['samtools', 'index', ANALYSIS_OUTPUT + str(iteration) + 'sorted.bam'])\n",
    "\n",
    "    with open(FILTERED_OUTPUT + str(iteration) + 'sorted.bam', 'w') as f:\n",
    "        subprocess.call(['samtools', 'sort', FILTERED_OUTPUT + str(iteration) + '.sam'], stdout=f)\n",
    "\n",
    "    subprocess.run(['samtools', 'index', FILTERED_OUTPUT + str(iteration) + 'sorted.bam'])\n",
    "\n",
    "    # read in indexed files and fetch reads inside windows\n",
    "\n",
    "    unfiltered = pysam.AlignmentFile(ANALYSIS_OUTPUT + str(iteration) + 'sorted.bam', 'r')\n",
    "    filtered = pysam.AlignmentFile(FILTERED_OUTPUT + str(iteration) + 'sorted.bam', 'r')\n",
    "\n",
    "    for i in range(0, base_count, 1000):\n",
    "        filtered_count = len(list(filtered.fetch('chromosome_1', i, i+2000)))\n",
    "        unfiltered_count = len(list(unfiltered.fetch('chromosome_1', i, i+2000)))\n",
    "\n",
    "        window_counts.write('\\t'.join(map(str, [\n",
    "            iteration,\n",
    "            i,\n",
    "            i + 2000,\n",
    "            filtered_count,\n",
    "            unfiltered_count,\n",
    "            list(filter(lambda x: x>i and x<i+2000, phase_changes))\n",
    "        ])) + '\\n')\n",
    "        \n",
    "    iteration += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 400 sequence fasta and corresponding csv\n",
    "\n",
    "args = {}\n",
    "args['end'] = 1100000\n",
    "args['start'] = 1000000\n",
    "args['percent'] = 0.00004\n",
    "args['fasta'] = 'output/vcf2fasta.fasta'\n",
    "\n",
    "iteration = 1\n",
    "\n",
    "# parse results from vcf2fasta\n",
    "fasta_file = list(SeqIO.parse(args['fasta'], 'fasta'))\n",
    "\n",
    "# tsv for phase changes\n",
    "phase_change_tsv = open('output400/phase_changes.tsv', 'w')\n",
    "\n",
    "# regex to identify correct fasta reference_name\n",
    "chrom = re.search(r'chromosome_[0-9]{1,2}', str(fasta_file[0].id)).group()\n",
    "\n",
    "fastas = []\n",
    "\n",
    "for i in range(400):\n",
    "\n",
    "    events = r.poisson((args['end'] - args['start']) * args['percent'])\n",
    "    phase_changes = sorted(list(r.choice((args['end']- args['start']), size=events)))\n",
    "    \n",
    "    phase_change_tsv.write('sequence' + str(iteration) + '\\t' + str(phase_changes) + '\\n')\n",
    "\n",
    "    haplotype0 = str(fasta_file[0].seq)\n",
    "    haplotype1 = str(fasta_file[1].seq)\n",
    "\n",
    "    current = 0\n",
    "    idx = args['start']\n",
    "    recomb_seq = []\n",
    "\n",
    "    for base in zip(haplotype0, haplotype1):\n",
    "\n",
    "        # switch haplotype if idx in list phase_changes    \n",
    "        current = (current + 1) % 2 if idx in phase_changes else current\n",
    "        recomb_seq.append(base[current])\n",
    "\n",
    "        if idx >= args['end']:\n",
    "            break\n",
    "        else:\n",
    "            idx += 1\n",
    "\n",
    "    recomb_record = SeqRecord(\n",
    "        Seq(''.join(recomb_seq)),\n",
    "        id=chrom,\n",
    "        name='sequence_' + str(iteration),\n",
    "        description=chrom,\n",
    "        dbxrefs=fasta_file[0].dbxrefs,\n",
    "        features=fasta_file[0].features,\n",
    "        annotations=fasta_file[0].annotations,\n",
    "        letter_annotations=fasta_file[0].letter_annotations\n",
    "    )\n",
    "\n",
    "    fastas.append(recomb_record)\n",
    "    iteration += 1\n",
    "\n",
    "SeqIO.write(fastas, 'output400/400_generated_sequences.fasta', 'fasta')\n",
    "phase_change_tsv.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 64.85it/s] \n",
      " 13%|█▎        | 40890/318475 [01:09<07:52, 587.58it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "error loading tabix index for b'../data/filtered_full.vcf.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-705087c687b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfiltered_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mmidpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_midpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidpoint\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mwindow_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recombinant-reads/analysis/jimmy/power_analysis/classification.py\u001b[0m in \u001b[0;36mget_midpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# classify if read has not been already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# simplification of results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recombinant-reads/analysis/jimmy/power_analysis/classification.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, masking, vcf)\u001b[0m\n\u001b[1;32m    139\u001b[0m         self.variants_1 = check_variants(vcf, self.rec_1.reference_name, \n\u001b[1;32m    140\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreference_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                 self.rec_1.reference_start + self.rec_1.query_alignment_length)\n\u001b[0m\u001b[1;32m    142\u001b[0m         self.variants_2 = check_variants(vcf, self.rec_2.reference_name, \n\u001b[1;32m    143\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreference_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recombinant-reads/analysis/jimmy/power_analysis/filter.py\u001b[0m in \u001b[0;36mcheck_variants\u001b[0;34m(vcf_file_obj, chromosome, left_bound, right_bound)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mSilentVCF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrec\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvcf_file_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recombinant-reads/analysis/jimmy/power_analysis/filter.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mSilentVCF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrec\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvcf_file_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/cyvcf2/cyvcf2.pyx\u001b[0m in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: error loading tabix index for b'../data/filtered_full.vcf.gz'"
     ]
    }
   ],
   "source": [
    "# import classification new one I haven't uploaded to pypi\n",
    "# not good habit so don't do this if you're copying this script\n",
    "from classification import *\n",
    "\n",
    "# 400 coverage with 400 sequences\n",
    "\n",
    "VCF_FILEPATH = '../data/filtered_full.vcf.gz'\n",
    "window_counts_tsv = open('output400/window_counts.tsv', 'w')\n",
    "SEQUENCE400 = 'output400/400_generated_sequences.fasta'\n",
    "\n",
    "COVERAGE = 5\n",
    "INSERT = 100\n",
    "ART_OUTPUT = 'output400/unfiltered'\n",
    "FILTERED_OUTPUT = 'output400/filtered'\n",
    "\n",
    "iteration = 1\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "    # run art_illumina on 400 sequences with coverage 400\n",
    "    \n",
    "    subprocess.run(['art_illumina',\n",
    "                    '-f', str(COVERAGE),\n",
    "                    '-l', '250',\n",
    "                    '-ss', 'MSv1',\n",
    "                    '-i', SEQUENCE400,\n",
    "                    '-m', str(500 + INSERT),\n",
    "                    '-s', '1',\n",
    "                    '-o', ART_OUTPUT + str(iteration),\n",
    "                    '-M', '-p', '-sam', '-na', '-q'])\n",
    "\n",
    "    # run readcomb on 400 sequence output generated by art_illumina\n",
    "\n",
    "    subprocess.run(['readcomb-filter',\n",
    "                    '-b', ART_OUTPUT + str(iteration) + '.sam',\n",
    "                    '-v', VCF_FILEPATH,\n",
    "                    '-p', '4',\n",
    "                    '-o', FILTERED_OUTPUT + str(iteration)])\n",
    "    \n",
    "\n",
    "    # read in sam files and \n",
    "    \n",
    "    unfiltered_pairs = pairs_creation(ART_OUTPUT + str(iteration) + '.sam', VCF_FILEPATH)\n",
    "    filtered_pairs = pairs_creation(FILTERED_OUTPUT + str(iteration) + '.sam', VCF_FILEPATH)\n",
    "    \n",
    "    # call get_midpoint on all of them, this will take quite a long time so use tqdm\n",
    "    \n",
    "    #[[filtered, unfiltered], ...]\n",
    "    window_counts = [[0,0] for i in range(100)]\n",
    "    \n",
    "    for pair in tqdm(filtered_pairs):\n",
    "        midpoint = pair.get_midpoint()\n",
    "        window = int(midpoint // 1000)\n",
    "        window_counts[window][0] += 1\n",
    "    \n",
    "    for pair in tqdm(unfiltered_pairs):\n",
    "        midpoint = pair.get_midpoint()\n",
    "        window = int(midpoint // 1000)\n",
    "        window_counts[window][1] += 1\n",
    "        \n",
    "    for i in range(len(window_counts)):\n",
    "        window_counts_tsv.write('\\t'.join(map(str, [\n",
    "            iteration,\n",
    "            i * 1000,\n",
    "            (i + 1) * 1000,\n",
    "            window_counts[i][0],\n",
    "            window_counts[i][1]\n",
    "        ])) + '\\n'\n",
    "            \n",
    "        )\n",
    "        \n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
